{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  0.,  1.,  2.,  0.],\n",
      "          [ 0.,  3.,  4.,  5.,  0.],\n",
      "          [ 0.,  6.,  7.,  8.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0.,  9., 10., 11.,  0.],\n",
      "          [ 0., 12., 13., 14.,  0.],\n",
      "          [ 0., 15., 16., 17.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 18., 19., 20.,  0.],\n",
      "          [ 0., 21., 22., 23.,  0.],\n",
      "          [ 0., 24., 25., 26.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]],\n",
      "\n",
      "\n",
      "        [[[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 27., 28., 29.,  0.],\n",
      "          [ 0., 30., 31., 32.,  0.],\n",
      "          [ 0., 33., 34., 35.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 36., 37., 38.,  0.],\n",
      "          [ 0., 39., 40., 41.,  0.],\n",
      "          [ 0., 42., 43., 44.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]],\n",
      "\n",
      "         [[ 0.,  0.,  0.,  0.,  0.],\n",
      "          [ 0., 45., 46., 47.,  0.],\n",
      "          [ 0., 48., 49., 50.,  0.],\n",
      "          [ 0., 51., 52., 53.,  0.],\n",
      "          [ 0.,  0.,  0.,  0.,  0.]]]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Создаем входной массив из двух изображений RGB 3*3\n",
    "input_images = torch.tensor(\n",
    "      [[[[0,  1,  2],\n",
    "         [3,  4,  5],\n",
    "         [6,  7,  8]],\n",
    "\n",
    "        [[9, 10, 11],\n",
    "         [12, 13, 14],\n",
    "         [15, 16, 17]],\n",
    "\n",
    "        [[18, 19, 20],\n",
    "         [21, 22, 23],\n",
    "         [24, 25, 26]]],\n",
    "\n",
    "\n",
    "       [[[27, 28, 29],\n",
    "         [30, 31, 32],\n",
    "         [33, 34, 35]],\n",
    "\n",
    "        [[36, 37, 38],\n",
    "         [39, 40, 41],\n",
    "         [42, 43, 44]],\n",
    "\n",
    "        [[45, 46, 47],\n",
    "         [48, 49, 50],\n",
    "         [51, 52, 53]]]])\n",
    "\n",
    "\n",
    "def get_padding2d(input_images):\n",
    "    \n",
    "    input_shape = input_images.shape\n",
    "    padded_images = torch.cat((torch.zeros(input_shape[0], input_shape[1], 1, input_shape[3]),                                                       input_images,\n",
    "                                torch.zeros(input_shape[0], input_shape[1], 1, input_shape[3])), dim=2 ).float()\n",
    " \n",
    "    padded_images = torch.cat((torch.zeros(input_shape[0], input_shape[1], padded_images.shape[2],1),\n",
    "                                padded_images,\n",
    "                                torch.zeros(input_shape[0], input_shape[1], padded_images.shape[2], 1)), dim=3)\n",
    "    return padded_images\n",
    "\n",
    "\n",
    "correct_padded_images = torch.tensor(\n",
    "       [[[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  0.,  1.,  2.,  0.],\n",
    "          [0.,  3.,  4.,  5.,  0.],\n",
    "          [0.,  6.,  7.,  8.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0.,  9., 10., 11.,  0.],\n",
    "          [0., 12., 13., 14.,  0.],\n",
    "          [0., 15., 16., 17.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 18., 19., 20.,  0.],\n",
    "          [0., 21., 22., 23.,  0.],\n",
    "          [0., 24., 25., 26.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]],\n",
    "\n",
    "\n",
    "        [[[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 27., 28., 29.,  0.],\n",
    "          [0., 30., 31., 32.,  0.],\n",
    "          [0., 33., 34., 35.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 36., 37., 38.,  0.],\n",
    "          [0., 39., 40., 41.,  0.],\n",
    "          [0., 42., 43., 44.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]],\n",
    "\n",
    "         [[0.,  0.,  0.,  0.,  0.],\n",
    "          [0., 45., 46., 47.,  0.],\n",
    "          [0., 48., 49., 50.,  0.],\n",
    "          [0., 51., 52., 53.,  0.],\n",
    "          [0.,  0.,  0.,  0.,  0.]]]])\n",
    "\n",
    "# Проверка происходит автоматически вызовом следующего кода\n",
    "# (раскомментируйте для самостоятельной проверки,\n",
    "#  в коде для сдачи задания должно быть закомментировано):\n",
    "print(get_padding2d(input_images))\n",
    "print(torch.allclose(get_padding2d(input_images), correct_padded_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = torch.ones((5,3,4))\n",
    "aa = torch.cat((torch.zeros(5,1,4), aa, torch.zeros(5,1,4)), dim=1)\n",
    "aa = torch.cat((torch.zeros(5,5,1), aa, torch.zeros(5,5,1)), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
